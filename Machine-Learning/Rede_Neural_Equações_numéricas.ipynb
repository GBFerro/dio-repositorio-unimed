{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cKY_eA4k_MrO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_converter_to_tensor = transforms.ToTensor()\n",
        "\n",
        "get_dataset_train = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=format_converter_to_tensor)\n",
        "buffer_dataset_train = torch.utils.data.DataLoader(get_dataset_train, batch_size=64, shuffle=True)\n",
        "\n",
        "get_dataset_value = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=format_converter_to_tensor)\n",
        "buffer_dataset_value = torch.utils.data.DataLoader(get_dataset_value, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "eQzsMvYPAZhG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datareader_train = iter(buffer_dataset_train)\n",
        "\n",
        "imagens, etiquetas = datareader_train.next()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RXdBMRn7EdDS",
        "outputId": "405a73b8-68cf-4faa-a5db-0fa720838d4e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape)\n",
        "\n",
        "print(etiquetas[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dph501LxFX5B",
        "outputId": "72a6e690-fceb-445e-9984-7dd619c56c8a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128)\n",
        "    self.linear2 = nn.Linear(128, 64)\n",
        "    self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = self.linear3(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "E5u_QAmwhLiX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "  inicio = time()\n",
        "\n",
        "  criterio = nn.NLLLoss()\n",
        "  EPOCHS = 30\n",
        "  modelo.train()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "      imagens = imagens.view(imagens.shape[0], -1)\n",
        "      otimizador.zero_grad()\n",
        "\n",
        "      output = modelo(imagens.to(device))\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "\n",
        "      perda_instantanea.backward()\n",
        "\n",
        "      otimizador.step()\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "  print('Tempo de treino (min) = ', (time()-inicio)/60)"
      ],
      "metadata": {
        "id": "ZyFXyeajjOxS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1,784)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device))\n",
        "\n",
        "      ps = torch.exp(logps)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab))\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if (etiqueta_certa == etiqueta_pred):\n",
        "        conta_corretas += 1\n",
        "      conta_todas += 1\n",
        "\n",
        "  print(f'Total de imagens testadas = {conta_todas}')\n",
        "  print('Precisão do modelo = {}%'.format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "_ZsK0U5CnizY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAC7OuYzp0bd",
        "outputId": "1473b036-decf-47f7-866f-70df55bbb99a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treino(modelo, buffer_dataset_train, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvqUIXQQqiQn",
        "outputId": "d63dd7fc-583f-48b6-ec0e-8093cc79f4a2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de treino (min) =  4.118900644779205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validacao(modelo, buffer_dataset_value, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxoEVR4Rv4Wj",
        "outputId": "8eb50670-6084-4ca4-91cd-06a671e759a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens testadas = 10000\n",
            "Precisão do modelo = 97.45%\n"
          ]
        }
      ]
    }
  ]
}